# DreamWalker
Using a non‐invasive method (EEG) to access brain signals, we can harness generative AI, deep learning, and large language models to usher human communication into a new era of telecommunications.
![Telepathy drawio](https://github.com/user-attachments/assets/0d18038b-8364-4d11-83b1-c3d4c1339721)

Deam walker is trained using the dataset created by https://doi.org/10.1016/j.neuroimage.2022.119754

@article{GIFFORD2022119754,
  title = {A large and rich EEG dataset for modeling human visual object recognition},
  journal = {NeuroImage},
  volume = {264},
  pages = {119754},
  year = {2022},
  issn = {1053-8119},
  doi = {https://doi.org/10.1016/j.neuroimage.2022.119754},
  url = {https://www.sciencedirect.com/science/article/pii/S1053811922008758},
  author = {Alessandro T. Gifford and Kshitij Dwivedi and Gemma Roig and Radoslaw M. Cichy},
  keywords = {Artificial neural networks, Computational neuroscience, Electroencephalography, Open-access data resource, Neural encoding models, Visual object recognition},
  abstract = {The human brain achieves visual object recognition through multiple stages of linear and nonlinear transformations operating at a millisecond scale. To predict and explain these rapid transformations, computational neuroscientists employ machine learning modeling techniques. However, state-of-the-art models require massive amounts of data to properly train, and to the present day there is a lack of vast brain datasets which extensively sample the temporal dynamics of visual object recognition. Here we collected a large and rich dataset of high temporal resolution EEG responses to images of objects on a natural background. This dataset includes 10 participants, each with 82,160 trials spanning 16,740 image conditions. Through computational modeling we established the quality of this dataset in five ways. First, we trained linearizing encoding models that successfully synthesized the EEG responses to arbitrary images. Second, we correctly identified the recorded EEG data image conditions in a zero-shot fashion, using EEG synthesized responses to hundreds of thousands of candidate image conditions. Third, we show that both the high number of conditions as well as the trial repetitions of the EEG dataset contribute to the trained models’ prediction accuracy. Fourth, we built encoding models whose predictions well generalize to novel participants. Fifth, we demonstrate full end-to-end training of randomly initialized DNNs that output EEG responses for arbitrary input images. We release this dataset as a tool to foster research in visual neuroscience and computer vision.}
}
